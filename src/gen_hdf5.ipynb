{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 35,
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 36,
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "def plotMesh(meshfile, arr, property):\n",
    "    p = pv.Plotter()\n",
    "    p.enable()\n",
    "    p.enable_anti_aliasing()\n",
    "\n",
    "    mesh = pv.read(meshfile)\n",
    "    mesh[property] = arr[:]\n",
    "    mesh.set_active_scalars(property)\n",
    "    p.add_mesh(mesh, opacity=0.85, render=True, cmap='plasma')\n",
    "    p.add_mesh(mesh.contour(), color=\"white\", line_width=2, render=True, cmap='plasma')\n",
    "\n",
    "    p.set_viewup([0, 1, 0])\n",
    "    #p.fly_to([5,0,0])\n",
    "\n",
    "    #p.set_position([5.0, -0.01, 7.5])\n",
    "    p.window_size = [1280,480]\n",
    "    #p.save_graphic('./annSU2_'+str(pod.modes.shape[1])+'_modes.pdf')\n",
    "    p.show(interactive_update=False, auto_close=True)\n",
    "    #p.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 37,
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import pyvista as pv\n",
    "import pandas as pd\n",
    "\n",
    "def _genHDF5(doe_file, outputfile, solutions_id):\n",
    "    # solutions indexes to be read\n",
    "    solutions_id \n",
    "\n",
    "    # read doe_file\n",
    "    pd.read_csv(doe_file, delimiter=',')\n",
    "\n",
    "    with h5py.File(outputfile, 'w') as snaps:\n",
    "        # create entries for every design variable in doe_file\n",
    "        pass\n",
    "\n",
    "def _genQ1DHDF5(path, variables, outputfile, solutions_id):\n",
    "    #path = path_ + 'Q1D/*'\n",
    "    print(f'Reading data from {path}, generating HDF5 file...')\n",
    "    #npaths = len(list(filter( os.path.isdir, glob.glob(f'{path}*') ))) \n",
    "\n",
    "    arrsize = len(np.loadtxt(f\"{path}/{1}/Q1D/outputs/{variables[0]}\"))\n",
    "    arrsize = arrsize*len(variables)\n",
    "\n",
    "    snaps = h5py.File(outputfile,'w')\n",
    "    snaps.create_dataset('snapshots', shape=(arrsize, len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('id', shape=(len(solutions_id)), dtype=np.int32)\n",
    "    #snaps.create_dataset('p0in', shape=(len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('T0in', shape=(len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('thickness', shape=(len(solutions_id)), dtype=np.float64)\n",
    "    \n",
    "    df = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe_params = list(df.keys())\n",
    "\n",
    "    for param in doe_params: \n",
    "        snaps.create_dataset(param, shape=(len(solutions_id)), dtype=type(df[param][0]))\n",
    "   \n",
    "\n",
    "    #for i in range(1, npaths+1):\n",
    "    for i,j in enumerate(solutions_id):\n",
    "        idx0 = 0\n",
    "        idxf = idx0\n",
    "        for var in variables:\n",
    "            #filename = path.split('*')[0]+str(i)+'/outputs/'+var\n",
    "            filename = f\"{path}/{j}/Q1D/outputs/{var}\"\n",
    "            print(f\"reading file {filename}\")\n",
    "            arr = np.loadtxt(filename)\n",
    "            idx0 = idxf\n",
    "            idxf = idx0 + len(arr)\n",
    "            snaps['snapshots'][idx0:idxf,i-1] = arr[:]\n",
    "    \n",
    "        #snaps['DoE'] = df\n",
    "\n",
    "        #snaps['id'][i] = j\n",
    "\n",
    "        doe_params = get_doe_parameters(f\"{path}/doe_lhs.txt\", j)\n",
    "       \n",
    "        for key, val in doe_params.items():\n",
    "            snaps[key][i] = val\n",
    "\n",
    "        #p0in, T0in, thickness = get_boundary_condition(f\"{path}/doe_lhs.txt\", j)\n",
    "        #snaps['p0in'][i] = p0in\n",
    "        #snaps['T0in'][i] = T0in\n",
    "        #snaps['thickness'][i] = thickness\n",
    "\n",
    "    snaps.close()\n",
    "\n",
    "    doe = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe.to_hdf(outputfile, key='DoE', mode='a', append=True)    \n",
    "\n",
    "    print(f'File {outputfile} written')\n",
    "\n",
    "def get_wall_idx(vtkfile):\n",
    "    output = pv.read(vtkfile)\n",
    "    #edges = output.extract_feature_edges()\n",
    "    edges = output\n",
    "    wall_idx = np.where(edges['Heat_Flux'] != 0)[0]\n",
    "    return wall_idx\n",
    "\n",
    "def genSU2HDF5_Fluid(path, vtkfile, variables, outputfile, solutions_id):\n",
    "    #path = path_ + 'SU2/*'\n",
    "    print(f'Reading data from {path}, generating HDF5 file...')\n",
    "    #npaths = len(list(filter( os.path.isdir, glob.glob(f'{path}*') )))\n",
    "\n",
    "    #mesh = pv.read(path.split('*')[0]+'1/outputs/solution.vtk')\n",
    "    mesh = pv.read(f\"{path}/1/SU2/outputs/{vtkfile}\")\n",
    "    if 'Heat_Flux' in variables:\n",
    "        wall_idx = get_wall_idx(f\"{path}/1/SU2/outputs/{vtkfile}\")\n",
    "        arrsize = len(mesh[variables[0]])\n",
    "        arrsize = arrsize*(len(variables)-1) + len(wall_idx)\n",
    "    else:\n",
    "        arrsize = len(mesh[variables[0]])\n",
    "        arrsize = arrsize*len(variables)\n",
    "\n",
    "    snaps = h5py.File(outputfile,'w')\n",
    "    snaps.create_dataset('snapshots', shape=(arrsize, len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('id', shape=(len(solutions_id)), dtype=np.int32)\n",
    "    #snaps.create_dataset('p0in', shape=(len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('T0in', shape=(len(solutions_id)), dtype=np.float64)\n",
    "    #snaps.create_dataset('thickness', shape=(len(solutions_id)), dtype=np.float64)\n",
    "\n",
    "    df = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe_params = list(df.keys())\n",
    "\n",
    "    for param in doe_params: \n",
    "        snaps.create_dataset(param, shape=(len(solutions_id)), dtype=type(df[param][0]))\n",
    "    \n",
    "    meshfiles=[]\n",
    "    for i,j in enumerate(solutions_id):\n",
    "        idx0 = 0\n",
    "        idxf = idx0\n",
    "        #filename = path.split('*')[0]+str(i)+'/outputs/solution.vtk'\n",
    "        filename = f\"{path}/{j}/SU2/outputs/{vtkfile}\"\n",
    "        meshfile = f\"{path}/{j}/SU2/outputs/{vtkfile.split('.vtk')[0]}_mesh.vtk\"\n",
    "        print(f'reading file {filename}')\n",
    "        mesh = pv.read(filename)\n",
    "        for var in variables:\n",
    "            if var == 'Heat_Flux':\n",
    "                arr = mesh[var][wall_idx]\n",
    "                \n",
    "                #import matplotlib.pyplot as plt\n",
    "                #print(var)\n",
    "                #print(mesh[var].shape)\n",
    "                #plotMesh(f\"{path}/{j}/SU2/outputs/{vtkfile}\", mesh[var], var)\n",
    "                #plt.plot(mesh[var][wall_idx])\n",
    "                #plt.show()\n",
    "                #input()\n",
    "                \n",
    "                idx0 = idxf\n",
    "                idxf = idx0 + len(arr)\n",
    "                snaps['snapshots'][idx0:idxf,i-1] = arr[:]\n",
    "            else:\n",
    "                arr = mesh[var]\n",
    "                idx0 = idxf\n",
    "                idxf = idx0 + len(arr)\n",
    "                snaps['snapshots'][idx0:idxf,i-1] = arr[:]\n",
    "        meshfiles.append(meshfile)\n",
    "\n",
    "        #snaps['id'][i] = j\n",
    "\n",
    "        doe_params = get_doe_parameters(f\"{path}/doe_lhs.txt\", j)\n",
    "       \n",
    "        for key, val in doe_params.items():\n",
    "            snaps[key][i] = val\n",
    "\n",
    "        #p0in, T0in, thickness = get_boundary_condition(f\"{path}/doe_lhs.txt\", j)\n",
    "        #snaps['p0in'][i] = p0in\n",
    "        #snaps['T0in'][i] = T0in\n",
    "        #snaps['thickness'][i] = thickness\n",
    "\n",
    "         \n",
    "\n",
    "    snaps.create_dataset(\"meshfile\", data=np.array(meshfiles, dtype='S'))\n",
    "    snaps.close()\n",
    "\n",
    "    doe = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe.to_hdf(outputfile, key='DoE', mode='a', append=True)\n",
    "\n",
    "    print(f'File {outputfile} written')\n",
    "\n",
    "def genSU2HDF5(path, vtkfile, variables, outputfile, solutions_id):\n",
    "    #path = path_ + 'SU2/*'\n",
    "    print(f'Reading data from {path}, generating HDF5 file...')\n",
    "    #npaths = len(list(filter( os.path.isdir, glob.glob(f'{path}*') )))\n",
    "\n",
    "    #mesh = pv.read(path.split('*')[0]+'1/outputs/solution.vtk')\n",
    "    mesh = pv.read(f\"{path}/1/SU2/outputs/{vtkfile}\")\n",
    "    arrsize = len(mesh[variables[0]])\n",
    "    arrsize = arrsize*len(variables)\n",
    "\n",
    "    snaps = h5py.File(outputfile,'w')\n",
    "    snaps.create_dataset('snapshots', shape=(arrsize, len(solutions_id)), dtype=np.float64)\n",
    "    snaps.create_dataset('id', shape=(len(solutions_id)), dtype=np.int32)\n",
    "\n",
    "    df = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe_params = list(df.keys())\n",
    "\n",
    "    for param in doe_params: \n",
    "        snaps.create_dataset(param, shape=(len(solutions_id)), dtype=type(df[param][0]))\n",
    "    \n",
    "        \n",
    "    meshfiles=[]\n",
    "    for i,j in enumerate(solutions_id):\n",
    "        idx0 = 0\n",
    "        idxf = idx0\n",
    "        #filename = path.split('*')[0]+str(i)+'/outputs/solution.vtk'\n",
    "        filename = f\"{path}/{j}/SU2/outputs/{vtkfile}\"\n",
    "        meshfile = f\"{path}/{j}/SU2/outputs/{vtkfile.split('.vtk')[0]}_mesh.vtk\"\n",
    "        print(f'reading file {filename}')\n",
    "        mesh = pv.read(filename)\n",
    "        for var in variables:\n",
    "            arr = mesh[var]\n",
    "            idx0 = idxf\n",
    "            idxf = idx0 + len(arr)\n",
    "            snaps['snapshots'][idx0:idxf,i-1] = arr[:]\n",
    "        meshfiles.append(meshfile)\n",
    "\n",
    "        snaps['id'][i] = j\n",
    "\n",
    "        #p0in, T0in, thickness = get_boundary_condition(f\"{path}/doe_lhs.txt\", j)\n",
    "        doe_params = get_doe_parameters(f\"{path}/doe_lhs.txt\", j)\n",
    "       \n",
    "        for key, val in doe_params.items():\n",
    "            snaps[key][i] = val\n",
    "        \n",
    "        #snaps['p0in'][i] = p0in\n",
    "        #snaps['T0in'][i] = T0in\n",
    "        #snaps['thickness'][i] = thickness\n",
    "\n",
    "    snaps.create_dataset(\"meshfile\", data=np.array(meshfiles, dtype='S'))\n",
    "    snaps.close()\n",
    "\n",
    "    doe = pd.read_csv(f\"{path}/doe_lhs.txt\")\n",
    "    doe.to_hdf(outputfile, key='DoE', mode='a', append=True)\n",
    "\n",
    "    print(f'File {outputfile} written')\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "def _get_converged_solutions(path):\n",
    "    # old implementations, dooest not take the solution filename for verification\n",
=======
    "def get_converged_solutions(root_path, solution_path):\n",
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
    "    solutions_id = []\n",
    "    n_directories = len(list(filter( os.path.isdir, glob.glob(f'{root_path}/*') ))) \n",
    "    for i in range(n_directories):\n",
    "        solution_file = f'{root_path}/{i+1}/{solution_path}'\n",
    "        if len(list( glob.glob(f'{solution_file}*') )) > 0:\n",
    "            solutions_id.append(i+1)\n",
    "\n",
    "    return solutions_id\n",
    "\n",
    "def get_converged_solutions(path, after_path):\n",
    "    solutions_id = []\n",
    "    n_directories = len(list(filter( os.path.isdir, glob.glob(f'{path}/*') ))) \n",
    "    for i in range(n_directories):\n",
    "        solution_file = f'{path}/{i+1}{after_path}'\n",
    "        if len(list( glob.glob(f'{solution_file}*') )) > 0:\n",
    "            solutions_id.append(i+1)\n",
    "\n",
    "    return solutions_id\n",
    "\n",
    "def get_boundary_condition(doe_file, id):\n",
    "    #dataset_root = '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200'\n",
    "    #id = 6 # case to run\n",
    "    #doe_file = '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200/doe_lhs.txt'\n",
    "    doe_table = np.loadtxt(doe_file, skiprows=1, delimiter=',')\n",
    "    idx = np.where(doe_table[:,0] == id) # idx related to case number\n",
    "\n",
    "    p0in = doe_table[idx,1][0][0]\n",
    "    T0in = doe_table[idx,2][0][0]\n",
    "    thickness = doe_table[idx,3][0][0]\n",
    "\n",
    "    return p0in, T0in, thickness\n",
    "\n",
    "def get_doe_parameters(doe_file, id):\n",
    "    df = pd.read_csv(doe_file, delimiter=',')\n",
    "\n",
    "    d = {}\n",
    "    for key in df.keys():\n",
    "        d[key] = df[df['ID']==id][key][0]\n",
    "    return d\n",
    "    #return tuple(d.values())\n",
    "\n",
    "def main():\n",
    "    \n",
    "    solutions_id = _get_converged_solutions('/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200')\n",
    "\n",
    "    genQ1DHDF5('/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200', \n",
    "               ['p.txt','T.txt','M.txt'],\n",
    "               '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200/Q1D.hdf5', \n",
    "               solutions_id)       \n",
    "    \n",
    "    genSU2HDF5_Fluid('/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200', \n",
    "               'fluid.vtk',\n",
    "               ['Pressure','Temperature','Mach','Heat_Flux'],\n",
    "               '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200/SU2_fluid.hdf5',\n",
    "               solutions_id)\n",
    "    \n",
    "    #genSU2HDF5('/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200', \n",
    "    #           'solid.vtk',\n",
    "    #           ['Temperature'],\n",
    "    #           '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200/SU2_solid.hdf5',\n",
    "    #           solutions_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doe_path = '/home/ppiper/ihtc_repository/data/doe_test'\n",
    "su2_after_path = '/SU2/outputs/cht_setupSU2.vtm'\n",
    "\n",
    "q1d_variables =  ['p.txt','T.txt','M.txt']\n",
    "d1d_hdf5_file =  f'{doe_path}Q1D.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions_id = get_converged_solutions(path=doe_path, after_path=su2_after_path)\n",
    "solutions_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from /home/ppiper/ihtc_repository/data/doe_test, generating HDF5 file...\n",
      "reading file /home/ppiper/ihtc_repository/data/doe_test/1/Q1D/outputs/p.txt\n",
      "reading file /home/ppiper/ihtc_repository/data/doe_test/1/Q1D/outputs/T.txt\n",
      "reading file /home/ppiper/ihtc_repository/data/doe_test/1/Q1D/outputs/M.txt\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pytables'.  Use pip or conda to install pytables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/site-packages/pandas/compat/_optional.py:142\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m genQ1DHDF5( path \u001b[39m=\u001b[39m doe_path, variables\u001b[39m=\u001b[39mq1d_variables, outputfile\u001b[39m=\u001b[39md1d_hdf5_file, \n\u001b[1;32m      2\u001b[0m             solutions_id \u001b[39m=\u001b[39m solutions_id)\n",
      "Cell \u001b[0;32mIn[7], line 59\u001b[0m, in \u001b[0;36mgenQ1DHDF5\u001b[0;34m(path, variables, outputfile, solutions_id)\u001b[0m\n\u001b[1;32m     56\u001b[0m snaps\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     58\u001b[0m doe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/doe_lhs.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m doe\u001b[39m.\u001b[39mto_hdf(outputfile, key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDoE\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, append\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)    \n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00moutputfile\u001b[39m}\u001b[39;00m\u001b[39m written\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/site-packages/pandas/core/generic.py:2682\u001b[0m, in \u001b[0;36mNDFrame.to_hdf\u001b[0;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m pytables\n\u001b[1;32m   2680\u001b[0m \u001b[39m# Argument 3 to \"to_hdf\" has incompatible type \"NDFrame\"; expected\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[39m# \"Union[DataFrame, Series]\" [arg-type]\u001b[39;00m\n\u001b[0;32m-> 2682\u001b[0m pytables\u001b[39m.\u001b[39mto_hdf(\n\u001b[1;32m   2683\u001b[0m     path_or_buf,\n\u001b[1;32m   2684\u001b[0m     key,\n\u001b[1;32m   2685\u001b[0m     \u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m   2687\u001b[0m     complevel\u001b[39m=\u001b[39mcomplevel,\n\u001b[1;32m   2688\u001b[0m     complib\u001b[39m=\u001b[39mcomplib,\n\u001b[1;32m   2689\u001b[0m     append\u001b[39m=\u001b[39mappend,\n\u001b[1;32m   2690\u001b[0m     \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m   2691\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[1;32m   2692\u001b[0m     min_itemsize\u001b[39m=\u001b[39mmin_itemsize,\n\u001b[1;32m   2693\u001b[0m     nan_rep\u001b[39m=\u001b[39mnan_rep,\n\u001b[1;32m   2694\u001b[0m     dropna\u001b[39m=\u001b[39mdropna,\n\u001b[1;32m   2695\u001b[0m     data_columns\u001b[39m=\u001b[39mdata_columns,\n\u001b[1;32m   2696\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m   2697\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   2698\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/site-packages/pandas/io/pytables.py:302\u001b[0m, in \u001b[0;36mto_hdf\u001b[0;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[1;32m    300\u001b[0m path_or_buf \u001b[39m=\u001b[39m stringify_path(path_or_buf)\n\u001b[1;32m    301\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 302\u001b[0m     \u001b[39mwith\u001b[39;00m HDFStore(\n\u001b[1;32m    303\u001b[0m         path_or_buf, mode\u001b[39m=\u001b[39mmode, complevel\u001b[39m=\u001b[39mcomplevel, complib\u001b[39m=\u001b[39mcomplib\n\u001b[1;32m    304\u001b[0m     ) \u001b[39mas\u001b[39;00m store:\n\u001b[1;32m    305\u001b[0m         f(store)\n\u001b[1;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/site-packages/pandas/io/pytables.py:560\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mformat is not a defined argument for HDFStore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m tables \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mtables\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39mif\u001b[39;00m complib \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m complib \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m tables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs:\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    564\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomplib only supports \u001b[39m\u001b[39m{\u001b[39;00mtables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs\u001b[39m}\u001b[39;00m\u001b[39m compression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/frenv/lib/python3.11/site-packages/pandas/compat/_optional.py:145\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pytables'.  Use pip or conda to install pytables."
     ]
    }
   ],
   "source": [
    "genQ1DHDF5( path = doe_path, variables=q1d_variables, outputfile=d1d_hdf5_file, \n",
    "            solutions_id = solutions_id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     \n",
    "\n",
    "genSU2HDF5_Fluid('/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200', \n",
    "            'fluid.vtk',\n",
    "            ['Pressure','Temperature','Mach','Heat_Flux'],\n",
    "            '/home/ppiper/Dropbox/local/ihtc_nozzle/data/doe_lhs_N200/SU2_fluid.hdf5',\n",
    "            solutions_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "multiblock = pv.read('/home/ppiper/ihtc_repository/data/doe_test/1/SU2/outputs/cht_setupSU2.vtm')"
=======
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def get_q1d_variable(solution_path, variable_name):\n",
    "    solution_subpath = solution_path / 'Q1D' / 'outputs'\n",
    "    name_to_variable_conversion = {\n",
    "        'Pressure': np.loadtxt(solution_subpath / 'p.txt'),\n",
    "        'Temperature': np.loadtxt(solution_subpath / 'T.txt') ,\n",
    "        'Mach' : np.loadtxt(solution_subpath / 'M.txt'),\n",
    "    }\n",
    "    return name_to_variable_conversion[variable_name]\n",
    "\n",
    "def get_block_recursive(block, name_index):\n",
    "    for n in name_index:\n",
    "        block = block[n]\n",
    "    return block\n",
    "\n",
    "def get_su2_variable(solution_path, variable_name):\n",
    "    block = pv.read(solution_path)\n",
    "    name_to_variable_conversion ={\n",
    "        'Pressure' : \n",
    "            ['Zone 0 (Comp. Fluid)','Internal','Internal','Pressure'],\n",
    "        'Temperature' :\n",
    "            ['Zone 0 (Comp. Fluid)','Internal','Internal','Temperature'],\n",
    "        'Mach' : \n",
    "            ['Zone 0 (Comp. Fluid)','Internal','Internal','Mach'] ,\n",
    "        'Temperature_Solid' :\n",
    "            ['Zone 1 (Solid Heat)', 'Internal', 'Internal', 'Temperature'] ,\n",
    "        'Temperature_Solid_INNERWALL' : \n",
    "            ['Zone 1 (Solid Heat)', 'Boundary', 'INNERWALL', 'Temperature'] ,\n",
    "        'Heat_Flux_UPPER_WALL' : \n",
    "            ['Zone 0 (Comp. Fluid)', 'Boundary','UPPER_WALL', 'Heat_Flux'] ,\n",
    "    }\n",
    "\n",
    "    return  get_block_recursive( block, name_to_variable_conversion[variable_name])"
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "multiblock.keys()"
=======
    "def genHDF5(dataset_path, variables, outputfile, solutions_id, variable_getter, doe_file):\n",
    "    doe_ds = pd.read_csv(doe_file, delimiter=',').set_index('ID')\n",
    "\n",
    "    with h5py.File(outputfile, 'w') as h5file:\n",
    "        for key in doe_ds.keys():\n",
    "            h5file[key] = doe_ds[key]\n",
    "\n",
    "        for id in solutions_id:\n",
    "            for variable_name in variables:\n",
    "                solution_path = pathlib.Path(dataset_path / str(id))\n",
    "                variable_data = variable_getter(solution_path, variable_name)\n",
    "\n",
    "                if id == 1:\n",
    "                    h5file.create_dataset(variable_name,shape=(len(variable_data), len(solutions_id)))\n",
    "                    \n",
    "                h5file[variable_name][...,id-1] = variable_data\n",
    "\n"
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock['Zone 0 (Comp. Fluid)']['Internal']['Internal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multiblock['Zone 1 (Solid Heat)']['Boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "points = multiblock['Zone 1 (Solid Heat)']['Boundary']['INNERWALL'].points\n",
    "data =  multiblock['Zone 1 (Solid Heat)']['Boundary']['INNERWALL']['Temperature']\n",
    "\n",
    "idx_sort = np.argsort(points[:,0])\n",
    "points[:,0] = points[idx_sort,0]\n",
    "points[:,1] = points[idx_sort,1]\n",
    "data = data[idx_sort]\n",
    "\n",
    "plt.plot(points[:,0], data)\n",
    "#plt.plot(points[:,0], points[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter()\n",
    "mesh_fluid = multiblock['Zone 0 (Comp. Fluid)']['Internal']['Internal']\n",
    "mesh_fluid.set_active_scalars('Pressure')\n",
    "mesh_solid = multiblock['Zone 1 (Solid Heat)']['Internal']['Internal']\n",
    "mesh_solid.set_active_scalars('Temperature')\n",
    "pl.add_mesh(mesh_fluid)\n",
    "pl.add_mesh(mesh_solid)\n",
    "pl.show(cpos='xy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock['Zone 0 (Comp. Fluid)']['Internal']['Internal']['Pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock.GetBlock(0)[1][1]['Density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock.GetBlock(0).set_active_scalars('Pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock.GetBlock(0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock[0][0][0].set_active_scalars('Pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File (/home/ppiper/Dropbox/local/ihtc_repository/data/doe_30/1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 35\u001b[0m\n\u001b[1;32m     24\u001b[0m doe_file \u001b[39m=\u001b[39m dataset_path \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdoe_lhs.txt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     26\u001b[0m genHDF5(\n\u001b[1;32m     27\u001b[0m         doe_file \u001b[39m=\u001b[39m doe_file,\n\u001b[1;32m     28\u001b[0m         dataset_path \u001b[39m=\u001b[39m dataset_path, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         variable_getter \u001b[39m=\u001b[39m get_q1d_variable\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m genHDF5(\n\u001b[1;32m     36\u001b[0m         doe_file \u001b[39m=\u001b[39m doe_file, \n\u001b[1;32m     37\u001b[0m         dataset_path \u001b[39m=\u001b[39m dataset_path,\n\u001b[1;32m     38\u001b[0m         variables \u001b[39m=\u001b[39m su2_variables, \n\u001b[1;32m     39\u001b[0m         outputfile \u001b[39m=\u001b[39m su2_outputfile,\n\u001b[1;32m     40\u001b[0m         solutions_id \u001b[39m=\u001b[39m solutions_id, \n\u001b[1;32m     41\u001b[0m         variable_getter \u001b[39m=\u001b[39m get_su2_variable )\n",
      "Cell \u001b[0;32mIn[39], line 11\u001b[0m, in \u001b[0;36mgenHDF5\u001b[0;34m(dataset_path, variables, outputfile, solutions_id, variable_getter, doe_file)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m variable_name \u001b[39min\u001b[39;00m variables:\n\u001b[1;32m     10\u001b[0m     solution_path \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(dataset_path \u001b[39m/\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m     variable_data \u001b[39m=\u001b[39m variable_getter(solution_path, variable_name)\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     14\u001b[0m         h5file\u001b[39m.\u001b[39mcreate_dataset(variable_name,shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(variable_data), \u001b[39mlen\u001b[39m(solutions_id)))\n",
      "Cell \u001b[0;32mIn[38], line 18\u001b[0m, in \u001b[0;36mget_su2_variable\u001b[0;34m(solution_path, variable_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_su2_variable\u001b[39m(solution_path, variable_name):\n\u001b[0;32m---> 18\u001b[0m     block \u001b[39m=\u001b[39m pv\u001b[39m.\u001b[39mread(solution_path)\n\u001b[1;32m     19\u001b[0m     name_to_variable_conversion \u001b[39m=\u001b[39m{\n\u001b[1;32m     20\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mPressure\u001b[39m\u001b[39m'\u001b[39m : \n\u001b[1;32m     21\u001b[0m             [\u001b[39m'\u001b[39m\u001b[39mZone 0 (Comp. Fluid)\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mInternal\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mInternal\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPressure\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m             [\u001b[39m'\u001b[39m\u001b[39mZone 0 (Comp. Fluid)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBoundary\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mUPPER_WALL\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHeat_Flux\u001b[39m\u001b[39m'\u001b[39m] ,\n\u001b[1;32m     32\u001b[0m     }\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m  get_block_recursive( block, name_to_variable_conversion[variable_name])\n",
      "File \u001b[0;32m~/micromamba/envs/flowrec/lib/python3.11/site-packages/pyvista/utilities/fileio.py:167\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, attrs, force_ext, file_format, progress_bar)\u001b[0m\n\u001b[1;32m    165\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\u001b[39mstr\u001b[39m(filename)))\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(filename):\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile (\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m) not found\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39m# Read file using meshio.read if file_format is present\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m file_format:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File (/home/ppiper/Dropbox/local/ihtc_repository/data/doe_30/1) not found"
     ]
    }
   ],
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   "source": [
    "dataset_path = pathlib.Path('/home/ppiper/Dropbox/local/ihtc_repository/data/doe_30')\n",
    "\n",
    "su2_solution_file = pathlib.Path('SU2/outputs/cht_setupSU2.vtm')\n",
    "solutions_id = get_converged_solutions(dataset_path, su2_solution_file)\n",
    "\n",
    "q1d_variables = [\n",
    "        'Pressure',\n",
    "        'Temperature',\n",
    "        'Mach' \n",
    "]\n",
    "\n",
    "su2_variables = [\n",
    "        'Pressure', \n",
    "        'Temperature', \n",
    "        'Mach', \n",
    "        'Temperature_Solid', \n",
    "        'Temperature_Solid_INNERWALL', \n",
    "        'Heat_Flux_UPPER_WALL'\n",
    "]\n",
    " \n",
    "q1d_outputfile = pathlib.Path(dataset_path / 'q1d.h5')\n",
    "su2_outputfile = pathlib.Path(dataset_path / 'su2.h5')\n",
    "\n",
    "doe_file = dataset_path / 'doe_lhs.txt'\n",
    "\n",
    "genHDF5(\n",
    "        doe_file = doe_file,\n",
    "        dataset_path = dataset_path, \n",
    "        variables = q1d_variables,\n",
    "        outputfile = q1d_outputfile, \n",
    "        solutions_id = solutions_id,\n",
    "        variable_getter = get_q1d_variable\n",
    ")\n",
    "\n",
    "genHDF5(\n",
    "        doe_file = doe_file, \n",
    "        dataset_path = dataset_path,\n",
    "        variables = su2_variables, \n",
    "        outputfile = su2_outputfile,\n",
    "        solutions_id = solutions_id, \n",
    "        variable_getter = get_su2_variable )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock.plot()"
=======
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Pressure\": shape (401, 30), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/home/ppiper/Dropbox/local/ihtc_repository/data/doe_30/q1d.h5','r') as h5file:\n",
    "    print(h5file['Pressure'])"
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(multiblock[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiblock.set_active_scalars('PRESSURE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['CP3_y', 'Mach', 'Pressure', 'Temperature', 'Thickness']>\n"
     ]
    }
   ],
>>>>>>> 08270aa620c69fa514a92b3963a9ce160606b4b8
   "source": [
    "with h5py.File('/home/ppiper/Dropbox/local/ihtc_repository/data/doe_30/q1d.h5','r') as h5file:\n",
    "    print(h5file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c25544d719d175344236f55a7b30dc3b0a2e294f8af427f95c30844b0f4cb7f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
